%% @Introduce  : 
%% @File       : LiteratureReview.tex
%% @Author     : ryrl
%% @Email      : ryrl970311@gmail.com
%% @Time       : 2025/01/15 13:58
%% @Description: Literature Review


Causal inference combined with Graph Neural Networks (GNNs) for reconstructing gene regulatory networks (GRNs) from single-cell omics data is now a rapidly advancing field \cite{zevcevic2021relating,chen2022graph}. Traditional correlation-based methods, such as those employing Pearson correlation or mutual information, and tools like SCENIC \cite{aibar2017scenic,bravo2023scenic}, while effective at identifying gene co-expression patterns, often fail to distinguish between direct and indirect regulatory relationships, leading to the inclusion of spurious edges \cite{badia2023gene,shu2021modeling,li2023single}. Furthermore, these methods typically lack explicit mechanisms to model the inherent causality within GRNs, making it challenging to predict the impact of perturbations or discern cause-and-effect relationships \cite{shu2021modeling}. These limitations are compounded by the technical noise, sparsity, and dropout events prevalent in single-cell RNA sequencing (scRNA-seq) data \cite{lei2024deepgrncs,dai2024gene,mao2023predicting}. While model-based approaches like Boolean and Bayesian networks, and regression-based methods such as GENIE3 \cite{huynh2010inferring} and GRNBoost2 \cite{moerman2019grnboost2}, offer alternative frameworks, they often suffer from parameter dependency, computational complexity, assumptions about data distributions, or an inability to fully capture the complexity of regulatory mechanisms \cite{lei2024deepgrncs,badia2023gene} (Table \ref{tab:MethodComparison}).

The integration of causal inference \cite{pearl2009causal} with the representational power of GNNs \cite{wein2021graph} offers a promising approach to overcome these limitations. Causal inference aims to uncover the underlying mechanisms of gene regulation, moving beyond mere statistical associations. GNNs, with their ability to model complex graph-structured data, are well-suited for capturing the intricate dependencies within GRNs and have shown potential in handling the noise and sparsity inherent in single-cell data by leveraging network structure for information propagation and noise smoothing \cite{zhao2022hybrid,wang2021scgnn,gu2022scgnn}. Moreover, GNNs can naturally model non-linear relationships often missed by linear approaches \cite{mercatelli2020gene,otal2024analysis,feng2023gene}. Some methods initialize GRN structures based on prior knowledge and then use GNN-based encoders like Graph Convolutional Networks (GCNs) to refine gene features and identify interdependencies \cite{mao2023predicting,mao2023gene,zhao2021comprehensive,keyl2023single,cao2022multi}.


For instance, GENELink \cite{chen2022graph} employs a supervised learning approach using the Graph Attention Network (GAT) to learn low-dimensional embeddings of genes from scRNA-seq data and prior interaction knowledge (Figure \ref{fig:application}A, Table \ref{tab:MethodComparison}). These embeddings are then used for downstream tasks such as similarity measurement and causal inference of gene regulation. The attention mechanism in GAT allows the model to adaptively weight the importance of neighboring genes, potentially mitigating the effects of data sparsity. In contrast, CgNN \cite{du2024causal} presents a GNN-driven instrumental variable (IV) approach (Figure \ref{fig:application}B). It leverages the network structure itself as an instrument to address the challenge of hidden confounders, enabling the estimation of direct and indirect causal effects of treatments within the network. This approach directly tackles the confounding noise issue that challenges traditional correlation-based methods. Both GENELink and CgNN demonstrate the advantage of using GNNs to integrate gene expression features with network topology for improved GRN inference and causal effect estimation.

However, despite these advancements, significant challenges remain in effectively and systematically integrating causal inference principles with GNN architectures, particularly when faced with the extreme heterogeneity of single-cell data. Most existing methods, like those mentioned above, primarily focus on static snapshots of cellular states, often neglecting the crucial temporal dynamics of gene regulation that unfold during processes like development or disease progression \cite{nguyen2021comprehensive,keil2024review}. This limitation can mask the identification of key causal drivers and regulatory mechanisms that are inherently dynamic. Furthermore, while incorporating prior knowledge through GNNs is beneficial, the inherent noise and heterogeneity in single-cell omics data can still lead to overfitting or the misidentification of spurious regulatory edges \cite{wang2023gene}. Current causal inference strategies often rely on simplifying assumptions, such as linearity or specific partial correlation structures \cite{tran2022scremote,badia2023gene,wen2023applying}, which may fail to capture the complex, non-linear, and context-dependent nature of biological regulatory systems \cite{shojaee2023robust,jereesh2024reconstruction,yazdani2020mendelianrandomizationcausalnetworks}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{figures/ApplicationOfGNNCausal.pdf}
    \caption{
        Illustrative applications of GNNs in causal inference.
        A. CgNN framework use a graph as input and combines the GAT with instrumental variable (IV) to remove hidden confounders and estimate causal effects.
        B. GENELink processes gene expression and TF-gene adjacency matrices through stacked GAT layers with multi-head attention, generating low-dimensional embeddings for causal GRN reconstruction.
        % C.  GLUE framework integrates unpaired multi-omics data using omics-specific VAEs guided by a knowledge graph and adversarial alignment, generating unified embeddings for regulatory inference.
        % D.  GRN inference pipeline processes gene expression matrix through parallel non-linear and linear pathways employing GraphSAGE and link prediction, followed by Additive Noise Model (ANM) and ensemble methods for final network construction.
    }
    \label{fig:application}
\end{figure}

The field has seen a clear progression from correlation-based methods to model-based and regression-based approaches, and more recently, to the integration of machine learning, particularly GNNs, with causal inference frameworks for GRN reconstruction. Early GNN-based methods often focused on link prediction, aiming to identify potential regulatory interactions by leveraging network structure and gene features. More recent works, such as CgNN \cite{du2024causal}, are explicitly incorporating causal inference techniques like instrumental variables to address confounding and infer causal effects. Another emerging trend involves using GNNs for tasks beyond simple link prediction, such as identifying causal driver genes and performing computational intervention analysis \cite{tejada2023causal,deshpande2022network}. Methods like DeepGRNCS \cite{lei2024deepgrncs} are exploring cell subpopulation-specific regulation by training models to predict gene expression based on transcription factor activity.

Despite this progress, several key limitations highlight the need for further research. A major open question is how to effectively model the dynamic nature of GRNs using GNNs and causal inference, moving beyond static datasets to capture temporal dependencies. Addressing the inherent noise and heterogeneity of single-cell data while avoiding overfitting remains a significant challenge. Developing causal inference strategies that can capture non-linear and context-dependent regulatory mechanisms is also crucial. Furthermore, the interpretability of complex GNN models and the validation of inferred causal relationships in biological systems are ongoing areas of research. Future work should focus on developing novel GNN architectures and causal inference techniques that are specifically tailored to the unique challenges of single-cell omics data, enabling a more robust and accurate reconstruction of gene regulatory networks and a deeper understanding of their causal underpinnings.

\begin{table}[htbp]

    \centering
    \caption{Comparative analysis of GRN inference methods}
    \label{tab:MethodComparison}
    
    \begin{tblr}
        {
            width=\textwidth,
            colspec={Q[3cm, c, m] Q[5.5cm, c, m] Q[1cm, c, m] Q[5.5cm, c, m] Q[1cm, c, m]},
            row{1}={font=\bfseries},
      }
    \hline
        Method & Core Approach & Causality & Limitations & Year \\
    \hline
        
        WGCNA \cite{langfelder2008wgcna} & {Weighted correlation network} & - & Confounding Noise & 2008 \\

        GENIE3 \cite{huynh2010inferring} & Tree-based ensemble & - & Sensitive to parameters & 2010 \\
        
        SCENIC \cite{aibar2017scenic} & {Co-expression \& TF motifs} & - & Motif Requirement & 2017 \\

        GRNBoost2 \cite{moerman2019grnboost2} & Gradient Boosting Machine & - & Sensitive to hyperparameters & 2019 \\

        CNNC \cite{yuan2019deep} & Convolutional Neural Network & + & {Supervised Nature \&\\ Labeled Data Dependency} & 2019 \\
        
        Scribe \cite{qiu2020inferring} & Information theory-based & - & Requires Temporal Coupling & 2020 \\
        
        DeepMAPS \cite{ma2021deepmaps} & {Heterogeneity Graph Transformer} & - & Low Computational Efficiency & 2021 \\

        FigR \cite{kartha2022functional} & {Correlation \& TF motifs} & - & {Confounding Noise \&\\ Prior Knowledge Bias} & 2022 \\

        scREMOTE \cite{tran2022scremote} & {Regression} & - & Linear-only Modeling & 2022 \\

        GENELink \cite{chen2022graph} & Graph Attention Network & + & No Reliable Negatives & 2022 \\

        GLUE \cite{cao2022multi} & {Graph-Linked Embedding} & - & Sensitivity to Noise & 2022 \\

        Pando \cite{fleck2023inferring} & {Regression \& TF-gene prior} & - & {Linear-only Modeling \&\\ Prior knowledge biasi} & 2023 \\
        
        NME/cNME \cite{li2023single} & {Cross-Mapping Entropy} & + & High Computational Cost & 2023 \\
        
        Dictys \cite{wang2023dictys} & {Stochastic Differential Equation} & - & Linear-only Modeling & 2023 \\

        Swift-DynGFN \cite{nguyen2023causal} & Generative Flow Network & + & Limited Generalization & 2023 \\

        GRINCD \cite{feng2023gene} & {Graph Neural Network \& Additive Noise Model} & + & Initial Network Dependency & 2023 \\

        % CgNN \cite{du2024causal} & {Graph Neiral Network \&\\ Instrumental Variables} & + & Instrumental Variables Dependency & 2024 \\

        LINGER \cite{yuan2024inferring} & Neural Network & - & Reliance on known TF motifs & 2024 \\

        scMultiomeGRN \cite{xu2025deep} & Graph Convolutional Network & - & {Transcription Factors Only} & 2025 \\

        DigNet \cite{wang2025diffusion} & Diffusion-based Model & - & Random Sampling Variability & 2025 \\

        CIMLA \cite{dibaeinia2025interpretable} & {Machine Learning \&\\  Attribution Models} & + & Assumption Dependence & 2025 \\

    \hline
    \end{tblr}
\end{table}
